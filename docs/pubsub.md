# Pub/Sub：LISTEN / NOTIFY

## 概览
使用 PostgreSQL 内置的 `LISTEN/NOTIFY` 机制做轻量通知。示例采用“通知 id、回表取数据”的模式，确保消息可靠性。

关联实现：`sql/001_init.sql`（触发器 + pg_notify）、`src/pubsub.ts`。

## 原理与为什么可行
- `LISTEN channel` 订阅通道，`NOTIFY channel, payload` 发送通知。
- 通知在事务提交后送达，和写入同一事务能实现“写入 + 通知”的原子性。
- 适合作为“事件信号”，让订阅者去表里查询真相数据。

## 与普通表的区别
- 不是表读写行为，而是数据库内建的通知通道。
- 通知不持久、不可重放；普通表数据可查询、可重放。
- 需要保持长连接；普通表读写可短连接或连接池。

## 推荐维护策略
- **信号模式**：只发 id（或很小 payload），由订阅者回表查询完整数据。
- **重连策略**：监听连接断开后自动重连，避免漏消息。
- **连接池模式**：LISTEN 需要会话级连接，若使用 pgbouncer，需使用 session 模式或直连。
- **订阅监控**：通过 `pg_stat_activity` 监控监听连接数量与状态。

## 监控与告警建议
- **通知队列占用**：监控 `pg_notification_queue_usage()`，防止队列被塞满。
- **监听连接数**：关注 `pg_stat_activity` 中 `LISTEN` 会话数量与存活时间。
- **通知处理延迟**：应用侧统计“发送到处理”的延迟与丢失率。
- **连接稳定性**：监控断线重连次数与失败率。

## 参数与策略建议
- **payload 大小**：尽量保持小于 8KB，推荐只发 id/轻量字段。
- **通道命名**：固定白名单通道名，避免动态拼接带来的安全风险。
- **连接保活**：设置 TCP keepalive 或应用层心跳，避免空闲断开。
- **连接池规划**：预留专用连接给 LISTEN，避免被短连接挤占。

## 压测与验收建议
- **突发通知测试**：模拟高频 NOTIFY，验证通知丢失与延迟。
- **断线重连测试**：模拟网络抖动，确认重连后功能恢复。
- **回表读取压力**：验证订阅者在回表读取时的吞吐与延迟。

## 适用场景
- 实时通知、日志流、缓存失效信号、轻量事件广播。
- 需要“写入与通知原子性”的场景（触发器 + pg_notify）。

## 缺点 / 注意点
- **不保证可靠投递**：断线会漏通知，不适合当可靠消息队列。
- **payload 限制**：NOTIFY payload 有大小限制，适合小消息。
- **无背压**：发送方不会因订阅者处理慢而阻塞。
- **多节点扩展有限**：跨分片/多集群需额外机制。

## 更专业的替代方案：PGMQ

如果 `LISTEN/NOTIFY` 无法满足需求，可以考虑使用 [PGMQ](https://github.com/tembo-io/pgmq) —— 一个轻量级 PostgreSQL 消息队列扩展，类似 AWS SQS。

### 场景选择指南

| 场景 | 推荐方案 |
|------|----------|
| 简单实时通知、缓存失效信号 | `LISTEN/NOTIFY`（现有方案即可） |
| 需要可靠投递、不能丢消息 | **PGMQ** |
| 需要死信队列、消息重试 | **PGMQ** |
| 极高吞吐（10万+ msg/s） | 外部 Kafka / RabbitMQ |

### PGMQ vs LISTEN/NOTIFY

| 对比项 | LISTEN/NOTIFY | PGMQ |
|--------|---------------|------|
| 持久化 | ❌ 不持久，断连丢失 | ✅ 消息存表 |
| 可靠投递 | ❌ 无保证 | ✅ 可见性超时 + 重试 |
| 消息重放 | ❌ 不可重放 | ✅ 支持归档与重放 |
| 多消费者 | ❌ 广播模式 | ✅ 竞争消费 |
| 背压 | ❌ 无 | ✅ 消费者按需拉取 |
| 复杂度 | 低 | 中（需安装扩展） |

### PGMQ 核心特性

- **持久化**：消息存在表里，不会丢失
- **可见性超时**：消费者领取后有超时，超时未确认会重新可见
- **消息归档**：可保留历史消息、支持重放
- **长轮询**：`read_with_poll()` 等待新消息
- **多语言客户端**：Rust / Python / Go / JS / TS / Java / Elixir

### PGMQ 使用示例

```sql
-- 安装扩展
CREATE EXTENSION pgmq;

-- 创建队列
SELECT pgmq.create('my_queue');

-- 发送消息
SELECT pgmq.send('my_queue', '{"user_id": 123}'::jsonb);

-- 读取消息（可见性超时 30 秒）
SELECT * FROM pgmq.read('my_queue', 30, 1);

-- 确认删除（处理成功后调用）
SELECT pgmq.delete('my_queue', msg_id);

-- 归档（不删除，保留历史）
SELECT pgmq.archive('my_queue', msg_id);
```

### 何时升级到 PGMQ

- 业务要求"消息不能丢"
- 需要消费失败后自动重试
- 需要查询历史消息 / 消息重放
- 多个消费者竞争消费同一队列

## 附录：竞争消费者模式详解

**Competing Consumers Pattern（竞争消费者模式）** 是消息队列中最重要的设计模式之一，理解它有助于选择 LISTEN/NOTIFY 还是 PGMQ。

### 核心概念

```
                    ┌──────────────┐
                    │   Producer   │
                    │   (生产者)    │
                    └──────┬───────┘
                           │ 消息入队
                           ▼
                    ┌──────────────┐
                    │    Queue     │  ← 一个队列
                    │ [1][2][3][4] │
                    └──────┬───────┘
           ┌───────────────┼───────────────┐
           │               │               │
           ▼               ▼               ▼
     ┌──────────┐    ┌──────────┐    ┌──────────┐
     │ Worker 1 │    │ Worker 2 │    │ Worker 3 │  ← 多个消费者
     │ 处理 [1] │    │ 处理 [2] │    │ 处理 [3] │
     └──────────┘    └──────────┘    └──────────┘
```

**关键特性**：

- 每条消息**只被一个消费者处理**，不是广播给所有人
- 消费者之间是**竞争关系**，谁先领取谁处理
- 加更多消费者 = **水平扩展处理能力**

### 广播模式 vs 竞争消费模式

| 对比项 | LISTEN/NOTIFY（广播） | PGMQ（竞争消费） |
|--------|----------------------|------------------|
| 消息分发 | **所有**订阅者都收到同一消息 | **一个**消费者领取 |
| 处理次数 | 每个订阅者都处理一次（N 次） | 全局只处理一次（1 次） |
| 扩展效果 | 加订阅者 = 重复处理 | 加 Worker = 并行处理更多任务 |
| 消息分配 | 无控制，全量推送 | 按需拉取，自动负载均衡 |
| 典型用途 | 通知、信号、事件广播 | 任务分发、异步处理 |

### 两种模式的消息流对比

**广播模式（LISTEN/NOTIFY）**：

```
消息: "缓存失效: user:123"
      │
      ├──► 服务器 A: 清除本地缓存 ✓
      ├──► 服务器 B: 清除本地缓存 ✓
      └──► 服务器 C: 清除本地缓存 ✓
      
结果: 3 个服务器都执行了清除操作（这是期望的行为）
```

**竞争消费模式（PGMQ）**：

```
消息: "发送邮件给 user@example.com"
      │
      ├──► Worker A: 领取成功，发送邮件 ✓
      ├──► Worker B: 消息已被领取，跳过
      └──► Worker C: 消息已被领取，跳过
      
结果: 只有 1 个 Worker 发送了邮件（避免重复发送）
```

### 实际场景选择

| 场景 | 模式 | 原因 |
|------|------|------|
| 缓存失效通知 | 广播 | 所有节点都要清除本地缓存 |
| 配置更新通知 | 广播 | 所有服务都要重新加载配置 |
| WebSocket 消息推送 | 广播 | 所有网关都要转发给客户端 |
| 发送邮件/短信 | 竞争 | 每条消息只发一次 |
| 处理订单 | 竞争 | 每个订单只处理一次 |
| 视频转码任务 | 竞争 | 每个任务只执行一次 |
| 文件上传后处理 | 竞争 | 每个文件只处理一次 |
| 定时任务触发 | 竞争 | 避免多节点重复执行 |

### PGMQ 如何实现竞争消费

PGMQ 使用 **可见性超时（Visibility Timeout）** 机制确保消息不被重复消费：

```sql
-- 场景：3 个 Worker 同时从队列读取

-- Worker A 读取消息（设置 30 秒可见性超时）
SELECT * FROM pgmq.read('orders', 30, 1);
-- 返回: msg_id=1, message='{"order_id": 1001}'
-- 此时消息 1 对其他 Worker 不可见

-- Worker B 同时读取（拿到的是下一条）
SELECT * FROM pgmq.read('orders', 30, 1);
-- 返回: msg_id=2, message='{"order_id": 1002}'

-- Worker C 同时读取（继续下一条）
SELECT * FROM pgmq.read('orders', 30, 1);
-- 返回: msg_id=3, message='{"order_id": 1003}'

-- Worker A 处理完成，删除消息
SELECT pgmq.delete('orders', 1);

-- 如果 Worker B 在 30 秒内挂了没删除消息 2 会怎样？
-- → 30 秒后消息 2 自动重新可见
-- → Worker A 或 C 可以重新领取处理（自动重试）
```

### 可见性超时的工作流程

```
时间线
─────────────────────────────────────────────────────────────►
│
│  ┌─────────────────────────────────────┐
│  │ Worker A 读取消息（可见性超时 30s） │
│  └─────────────────────────────────────┘
│                    │
│                    ▼
│  ┌─────────────────────────────────────────────────────────┐
│  │         消息对其他 Worker 不可见（30 秒窗口）            │
│  └─────────────────────────────────────────────────────────┘
│                    │
│         ┌─────────┴─────────┐
│         ▼                   ▼
│  ┌────────────────┐  ┌─────────────────────────┐
│  │ 处理成功并删除 │  │ 超时未删除（Worker 挂了）│
│  │ → 消息消失     │  │ → 消息重新可见          │
│  │ → 处理完成 ✓   │  │ → 等待其他 Worker 领取  │
│  └────────────────┘  └─────────────────────────┘
```

### 竞争消费的优势

1. **水平扩展**：加 Worker 即可提升处理能力，无需改代码
2. **故障恢复**：Worker 挂了，消息自动被其他 Worker 重新处理
3. **负载均衡**：自动分配，处理快的 Worker 自然拿到更多消息
4. **精确一次**：在可见性超时内保证一条消息只被一个 Worker 处理

### 注意事项

- **幂等性**：消息可能被重试，业务逻辑应设计为幂等（多次执行结果一致）
- **超时设置**：可见性超时应大于最长处理时间，避免处理中被重新分配
- **死信队列**：多次重试仍失败的消息应移入死信队列，避免无限重试

## ⚠️ PGMQ 的性能陷阱与限制

> **核心问题**：PGMQ 本质是高频读写表，会产生大量 WAL 日志并给 Autovacuum 带来压力。

### 为什么 PGMQ 会有性能开销

PGMQ 的消息存储在普通 PostgreSQL 表中，每次操作都会：

| 操作 | 数据库行为 | 开销 |
|------|-----------|------|
| 发送消息（send） | INSERT 一行 | 写 WAL + 写表 |
| 读取消息（read） | UPDATE visibility timeout | 写 WAL + 写表 |
| 删除消息（delete） | DELETE 一行 | 写 WAL + 产生死行 |
| 归档消息（archive） | INSERT + DELETE | 双倍写入 |

这意味着：
- **每条消息至少产生 2-3 次 WAL 写入**（send → read → delete）
- **频繁 DELETE 会产生大量死行**，需要 Autovacuum 清理
- **高频队列可能成为数据库热点**，影响主库其他业务

### 不适合使用 PGMQ 的场景

| 场景 | 问题 | 替代方案 |
|------|------|----------|
| 即时鼠标轨迹/位置同步 | 极高频、低价值，拖累主库 | Redis Pub/Sub / WebSocket 直连 |
| 大量 Debug 日志收集 | 日志量巨大，不值得持久化 | Kafka / Loki / 文件日志 |
| 实时聊天消息（高并发） | 写入太频繁 | Redis Streams / 专用消息服务 |
| IoT 设备心跳/传感器数据 | 秒级数万条，压垮主库 | TimescaleDB / InfluxDB / Kafka |
| 视频/音频流数据 | 数据量大、实时性要求高 | 专用流媒体服务 |

### 性能阈值参考

| 吞吐量 | 建议 |
|--------|------|
| < 100 msg/s | ✅ PGMQ 完全可以胜任 |
| 100 - 1000 msg/s | ⚠️ 需要监控 WAL 和 Autovacuum |
| 1000 - 10000 msg/s | ⚠️ 考虑独立队列库或分区 |
| > 10000 msg/s | ❌ 应使用 Kafka / Redis Streams |

### 缓解措施

如果必须在数据库中跑高频队列，可以考虑：

1. **独立数据库**：队列表放在独立的 PostgreSQL 实例，不影响主库
   ```sql
   -- 队列专用库，与业务库隔离
   CREATE DATABASE queue_db;
   ```

2. **分区队列**：使用 `pg_partman` 按时间分区，加速清理
   ```sql
   SELECT pgmq.create_partitioned(
       'high_volume_queue',
       '1 hour'::interval,  -- 每小时一个分区
       '1 day'::interval    -- 保留 1 天
   );
   ```

3. **调整 Autovacuum 参数**：对队列表单独设置更激进的 vacuum
   ```sql
   ALTER TABLE pgmq.q_my_queue SET (
       autovacuum_vacuum_scale_factor = 0.01,      -- 1% 死行就触发
       autovacuum_vacuum_cost_delay = 0,           -- 不限速
       autovacuum_vacuum_cost_limit = 10000        -- 提高配额
   );
   ```

4. **批量操作**：减少单条写入，改用批量发送
   ```sql
   -- 批量发送多条消息
   SELECT pgmq.send_batch(
       'my_queue',
       ARRAY['{"id":1}'::jsonb, '{"id":2}'::jsonb, '{"id":3}'::jsonb]
   );
   ```

5. **监控告警**：持续监控队列表的健康状况
   ```sql
   -- 监控队列表的死行和膨胀
   SELECT 
       relname,
       n_live_tup,
       n_dead_tup,
       n_dead_tup::float / NULLIF(n_live_tup, 0) AS dead_ratio,
       last_autovacuum
   FROM pg_stat_user_tables
   WHERE schemaname = 'pgmq';
   ```

### 决策流程图

```
你的消息需要可靠投递吗？
        │
        ├── 不需要 → 用 LISTEN/NOTIFY（简单、无持久化开销）
        │
        └── 需要 → 消息频率是多少？
                        │
                        ├── < 1000/s → PGMQ ✅
                        │
                        └── > 1000/s → 消息价值高吗？
                                            │
                                            ├── 高价值 → PGMQ + 独立库 / 分区
                                            │
                                            └── 低价值 → Redis / Kafka
```

### 总结

PGMQ 是一个优秀的"中等负载可靠队列"方案，但不是银弹：

| 适合 | 不适合 |
|------|--------|
| 订单处理、邮件发送 | 实时日志流 |
| 异步任务调度 | 高频心跳/位置同步 |
| 低频但重要的事件 | 海量低价值数据 |
| 需要 ACID 保证的场景 | 极致性能优先的场景 |
